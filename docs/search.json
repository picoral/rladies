[
  {
    "objectID": "2023-09-15.html",
    "href": "2023-09-15.html",
    "title": "Reproducing Open Science Research 2",
    "section": "",
    "text": "September 15, 10am to 11am.\nFor this tutorial, we will be replicating some of the analysis in Palma, P., Marin, M. F., Onishi, K. H., & Titone, D. (2022). Learning, inside and out: Prior linguistic knowledge and learning environment impact word learning in bilingual individuals. Language Learning, 72(4), 980-1016. Paper can be found at https://onlinelibrary.wiley.com/doi/abs/10.1111/lang.12501\nData, code, and more information can be found at https://osf.io/69seu/"
  },
  {
    "objectID": "2023-09-15.html#descriptive-visualization-before-running-stats",
    "href": "2023-09-15.html#descriptive-visualization-before-running-stats",
    "title": "Reproducing Open Science Research 2",
    "section": "Descriptive visualization (before running stats)",
    "text": "Descriptive visualization (before running stats)\n\nWe hypothesized, first, that episodic memory for novel words may decrease over time.\n\n\nThe interval between experimental Day 1 and Day 2 was either 24 hours or 1 week.\n\n\ndata %&gt;% \n  group_by(Experiment, FC) %&gt;%\n  summarize(mean_acc = mean(ACC)) %&gt;% \n  mutate(diff = diff(mean_acc)) %&gt;% \n  ggplot(aes(x = FC,\n             y = mean_acc)) +\n  geom_line(aes(group = 1)) +\n  geom_label(aes(label = round(mean_acc, 2))) +\n  facet_wrap(~Experiment) +\n  labs(caption = \"procedure chart on page 990\")\n\n`summarise()` has grouped output by 'Experiment'. You can override using the\n`.groups` argument.\n\n\n\n\n\n\nResults from a model\nLet’s run a model with the effect of the interaction of Experiment and FC.\n\nmodel_experiment &lt;- glm(ACC ~ Experiment:FC,\n                        data = data,\n                        family = binomial)\n\nsummary(model_experiment)\n\n\nCall:\nglm(formula = ACC ~ Experiment:FC, family = binomial, data = data)\n\nCoefficients: (1 not defined because of singularities)\n                       Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)             0.59784    0.08394   7.122 1.06e-12 ***\nExperimentday1-2:FCFC1  0.89609    0.13482   6.646 3.00e-11 ***\nExperimentday1-8:FCFC1  0.57725    0.12535   4.605 4.12e-06 ***\nExperimentday1-2:FCFC2  0.55484    0.12721   4.362 1.29e-05 ***\nExperimentday1-8:FCFC2       NA         NA      NA       NA    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 2788.4  on 2459  degrees of freedom\nResidual deviance: 2738.8  on 2456  degrees of freedom\nAIC: 2746.8\n\nNumber of Fisher Scoring iterations: 4\n\n\nThe variance explained for this model is very low:\n\n# McFadden's R-squared for model\nwith(summary(model_experiment), 1 - deviance/null.deviance)\n\n[1] 0.01780274\n\n\nLet’s look at the effects:\n\nlibrary(effects)\n\nLoading required package: carData\n\n\nlattice theme set by effectsTheme()\nSee ?effectsTheme for details.\n\neffect(\"Experiment:FC\", model_experiment) %&gt;% \n  data.frame() %&gt;% \n   ggplot(aes(x = FC,\n             y = fit,\n             ymin = lower,\n             ymax = upper)) +\n  geom_line(aes(group = 1)) +\n  geom_errorbar() +\n  geom_label(aes(label = round(fit, 2))) +\n  facet_wrap(~Experiment)"
  },
  {
    "objectID": "2023-09-15.html#descriptive-visualization-before-running-stats-1",
    "href": "2023-09-15.html#descriptive-visualization-before-running-stats-1",
    "title": "Reproducing Open Science Research 2",
    "section": "Descriptive visualization (before running stats)",
    "text": "Descriptive visualization (before running stats)\n\nSecond, we hypothesized that, to the extent that neighborhood density in the learning environment impacts episodic memory, learning many novel neighbors for an existing word may lead to decreased episodic memory for these novel neighbors\n\n\ns1: one neighbor for List B base words (one-neighbor condition) and five neighbors for List C base words (five-neighbors condition). No neighbors were presented for List A base words (zero-neighbors condition).\ns2: one neighbor for List C and five for List A, whereas no neighbors were presented for List B base words.\ns3: one neighbor for List A and five for List B, whereas no neighbors were presented for List C base words.\n\nStimuli have either 1 or 5 neighbors:\n\ndata %&gt;% count(nb_neighbors)\n\n\n\n\n\nnb_neighbors\nn\n\n\n\n\n1\n1240\n\n\n5\n1220\n\n\n\n\n\n\n\ndata %&gt;% \n  group_by(FC, Experiment, nb_neighbors) %&gt;%\n  mutate(nb_neighbors = factor(nb_neighbors)) %&gt;% \n  summarize(mean_acc = mean(ACC)) %&gt;% \n  ggplot(aes(x = FC,\n             y = mean_acc,\n             color = nb_neighbors)) +\n  geom_line(aes(group = nb_neighbors)) +\n  geom_label(aes(label = round(mean_acc, 2))) +\n  facet_wrap(~Experiment) +\n  labs(caption = \"procedure chart on page 990\")\n\n`summarise()` has grouped output by 'FC', 'Experiment'. You can override using\nthe `.groups` argument.\n\n\n\n\n\n\ndata %&gt;% \n  group_by(FC, Experiment, Training_group) %&gt;%\n  summarize(mean_acc = mean(ACC)) %&gt;% \n  ggplot(aes(x = FC,\n             y = mean_acc,\n             color = Training_group)) +\n  geom_line(aes(group = Training_group)) +\n  geom_label(aes(label = round(mean_acc, 2))) +\n  facet_wrap(~Experiment) +\n  labs(caption = \"procedure chart on page 990\")\n\n`summarise()` has grouped output by 'FC', 'Experiment'. You can override using\nthe `.groups` argument.\n\n\n\n\n\n\nFinally, we hypothesized that, to the extent that cross-linguistic similarity impacts episodic memory, novel neighbors to words that overlap across languages may be easier to recognize."
  },
  {
    "objectID": "2023-09-29.html",
    "href": "2023-09-29.html",
    "title": "Reproducing Open Science Research 3",
    "section": "",
    "text": "October 06, 10am to 11am. Register\nFor this tutorial, we will be replicating some of the analysis in Chappell, W. & Kanwit, M. (2021). Do Learners Connect Sociophonetic Variation with Regional and Social Characteristics? The Case of L2 Perception of Spanish Aspiration. Studies in Second Language Acquisition. 44(1). 1–25.\nData can be found at https://www.iris-database.org/details/MQbI5-rz7z3"
  },
  {
    "objectID": "2023-09-29.html#participants",
    "href": "2023-09-29.html#participants",
    "title": "Reproducing Open Science Research 3",
    "section": "Participants",
    "text": "Participants\n\nSeventy-six language learners\n\nWe have multiple observations per participants, so to get to number of participants we need to use distinct()\n\nl2_span_perception %&gt;% \n  distinct(Participant) %&gt;% \n  nrow()\n\n[1] 76\n\n\nTable 1 recreation (page 193):\n\nl2_span_perception %&gt;% \n  distinct(Participant, Gender) %&gt;% \n  count(Gender)\n\n\n\n\n\nGender\nn\n\n\n\n\nFemale\n55\n\n\nMale\n21\n\n\n\n\n\n\n\nl2_span_perception %&gt;% \n  distinct(Participant, Age) %&gt;% \n  summarize(min_age = min(Age),\n            max_age = max(Age),\n            mean_age = mean(Age),\n            median_age = median(Age))\n\n\n\n\n\nmin_age\nmax_age\nmean_age\nmedian_age\n\n\n\n\n18\n57\n23.64474\n21\n\n\n\n\n\n\n\nl2_span_perception %&gt;% \n  distinct(Participant, Education) %&gt;% \n  count(Education, sort = TRUE)\n\n\n\n\n\nEducation\nn\n\n\n\n\nSome college\n43\n\n\nCollege graduate\n27\n\n\nHigh school\n5\n\n\nSome high school\n1"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R-Ladies Tucson",
    "section": "",
    "text": "Live Tutorials\n\nOctober 6, 2023: Reproducing Open Science Research 3\nSeptember 15, 2023: Reproducing Open Science Research 2\nSeptember 1, 2023: Reproducing Open Science Research 1\n\n\n\nRecorded Lessons\n\nReading and checking data in R"
  },
  {
    "objectID": "lesson-02.html",
    "href": "lesson-02.html",
    "title": "Reading multiple files in R",
    "section": "",
    "text": "For this tutorial on how to read data in R, we will be using bilingual children production from the (Corpus of bilingual children’s speech on kaggle)[https://www.kaggle.com/datasets/rtatman/corpus-of-bilingual-childrens-speech]"
  },
  {
    "objectID": "lesson-01.html",
    "href": "lesson-01.html",
    "title": "Reading and checking data",
    "section": "",
    "text": "For this tutorial on how to read data in R, we will be using the data available as complementary material for Tagliamonte’s (2011) Variationist Sociolinguistics: Change, Observation, Interpretation textbook.\nThis tutorial will be using posit.cloud for our IDE (Integrated Development Environment). You can create a free account to follow along.\n\nVideo demonstrations\n\n\n\n\nGetting started\nWe’ll be using two packages for this tutorial. RStudio should prompt you to install these once you save your .Rmd file.\n\nlibrary(tidyverse)\nlibrary(readxl)\n\nWe can now read our data in (remember to download the data from the website, and place it in a data folder in your project).\n\nthat_data &lt;- read_excel(\"data/data_set.xlsx\")\n\n\n\nHow many observations per participant?\nOnce you read your data, you should check to see if all your values are in the data. We can use count() for that.\n\nthat_data %&gt;% \n  count(Indiv, sort = TRUE)\n\n\n\n  \n\n\n\n\n\nChecking values of categorical variables\nWhen coding data, humans often make mistakes (misspell category names, for example). We can count how many of each dependent variable we have in our data using count() again.\n\nthat_data %&gt;% \n  count(Dep.var)\n\n\n\n  \n\n\n\nLet’s do the same with verbs.\n\nthat_data %&gt;% \n  count(Verbs.1)\n\n\n\n  \n\n\n\nThis data is of course very clean. I’ve changed the original data, to insert an error in one of the value names. We will read in that data, check the values, and make the changes to fix it.\nWe read the data in.\n\ncorrupt_data &lt;- read_excel(\"data/data_set_corrupt.xlsx\")\n\nThen we count the verbs. Notice the other value with one occurrence in our data.\n\ncorrupt_data %&gt;% \n  count(Verbs.1)\n\n\n\n  \n\n\n\nWe can certainly fix that in our original data file. But here’s how to fix it in R:\n\ncorrupt_data &lt;- corrupt_data %&gt;% \n  mutate(Verbs.1.fixed = case_when(Verbs.1 == \"other\" ~ \"OTHER\",\n                                   TRUE ~ Verbs.1))\n\nLet’s check our verbs again.\n\ncorrupt_data %&gt;% \n  count(Verbs.1.fixed)"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "R-Ladies Tucson AZ is part of a worldwide organization to promote Gender Diversity in the R statistical computing community. The mission of R-Ladies groups is to increase representation of women in global R community through establishing local communities providing mentorship, collaborative learning & support. Anyone with an interest in R is encouraged to participate. It doesn’t matter if you never used R or if you are an R expert. Come and join us!"
  },
  {
    "objectID": "2023-09-01.html",
    "href": "2023-09-01.html",
    "title": "Reproducing Open Science Research 1",
    "section": "",
    "text": "This tutorial took place on September 1, 2023. Here’s the session recording."
  },
  {
    "objectID": "2023-09-01.html#table-1-descriptive-statistics-for-the-perceived-mental-effort-scale",
    "href": "2023-09-01.html#table-1-descriptive-statistics-for-the-perceived-mental-effort-scale",
    "title": "Reproducing Open Science Research 1",
    "section": "Table 1 Descriptive statistics for the perceived mental effort scale",
    "text": "Table 1 Descriptive statistics for the perceived mental effort scale\nThe standard error is calculated by dividing the standard deviation by the sample size’s square root. The standard error is most useful as a means of calculating a confidence interval. For a large sample, a 95% confidence interval is obtained as the values 1.96×SE either side of the mean (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1255808).\n\nchild_l2_data %&gt;%\n  group_by(Group) %&gt;%\n  summarize(n = n(),\n            mean_ME_1 = mean(ME_1),\n            sd_ME_1 = sd(ME_1),\n            mean_ME_2 = mean(ME_2),\n            sd_ME_2 = sd(ME_2)) %&gt;%\n  mutate(lower_ci_ME_1 = mean_ME_1 - qt(1 - (.05 / 2), n - 1) * sd_ME_1/sqrt(n),\n         upper_ci_ME_1 = mean_ME_1 + qt(1 - (.05 / 2), n - 1) * sd_ME_1/sqrt(n),\n         lower_ci_ME_2 = mean_ME_2 - qt(1 - (.05 / 2), n - 1) * sd_ME_2/sqrt(n),\n         upper_ci_ME_2 = mean_ME_2 + qt(1 - (.05 / 2), n - 1) * sd_ME_2/sqrt(n))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGroup\nn\nmean_ME_1\nsd_ME_1\nmean_ME_2\nsd_ME_2\nlower_ci_ME_1\nupper_ci_ME_1\nlower_ci_ME_2\nupper_ci_ME_2\n\n\n\n\n1\n30\n3.833333\n1.743626\n3.433333\n1.715715\n3.182253\n4.484414\n2.792675\n4.073992\n\n\n2\n30\n5.933333\n1.910648\n5.233333\n2.358891\n5.219886\n6.646781\n4.352509\n6.114158"
  },
  {
    "objectID": "2023-09-01.html#table-4-results-for-the-linear-regression-models-examining-the-effects-of-task-complexity-on-the-oral-and-written-production-tests",
    "href": "2023-09-01.html#table-4-results-for-the-linear-regression-models-examining-the-effects-of-task-complexity-on-the-oral-and-written-production-tests",
    "title": "Reproducing Open Science Research 1",
    "section": "Table 4 Results for the linear regression models examining the effects of task complexity on the oral and written production tests",
    "text": "Table 4 Results for the linear regression models examining the effects of task complexity on the oral and written production tests\nThe way it is in the paper: group is a numeric variable\n\nmodel_1 &lt;- lm(ME_1 ~ Group, child_l2_data)\n\nlibrary(effects)\neffect(\"Group\", model_1) %&gt;%\n  data.frame()\n\n\n\n\n\nGroup\nfit\nse\nlower\nupper\n\n\n\n\n1.0\n3.833333\n0.3339362\n3.164887\n4.501779\n\n\n1.2\n4.253333\n0.2753709\n3.702119\n4.804548\n\n\n1.5\n4.883333\n0.2361286\n4.410671\n5.355996\n\n\n1.8\n5.513333\n0.2753709\n4.962119\n6.064548\n\n\n2.0\n5.933333\n0.3339362\n5.264887\n6.601779\n\n\n\n\n\n\n\n# linear regression (recreation of table 4 on page 200)\nmodel_table_4 &lt;- child_l2_data %&gt;%\n  lm(formula = Oral_Production_Post ~ Oral_Production_Pre + Group)\n\nsummary(model_table_4)\n\n\nCall:\nlm(formula = Oral_Production_Post ~ Oral_Production_Pre + Group, \n    data = .)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-41.942 -21.363  -4.573  21.869  66.482 \n\nCoefficients:\n                    Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)          44.0133    11.1696   3.940 0.000224 ***\nOral_Production_Pre   1.3947     0.4662   2.991 0.004099 ** \nGroup               -15.9727     6.9541  -2.297 0.025320 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 26.93 on 57 degrees of freedom\nMultiple R-squared:  0.2022,    Adjusted R-squared:  0.1742 \nF-statistic: 7.222 on 2 and 57 DF,  p-value: 0.001601\n\neffect(\"Group\", model_table_4) %&gt;%\n  data.frame() %&gt;%\n  ggplot(aes(x = Group,\n             y = fit,\n             ymin = lower,\n             ymax = upper)) +\n  geom_errorbar() +\n  geom_label(aes(label = format(fit, digits = 2)))\n\n\n\n\nThe correct way: group is a categorical (factor) variable\n\nchild_l2_data &lt;- child_l2_data %&gt;%\n  mutate(group = factor(Group))\n\nmodel_1 &lt;- lm(ME_1 ~ group, child_l2_data)\n\neffect(\"group\", model_1) %&gt;%\n  data.frame()\n\n\n\n\n\ngroup\nfit\nse\nlower\nupper\n\n\n\n\n1\n3.833333\n0.3339362\n3.164887\n4.501779\n\n\n2\n5.933333\n0.3339362\n5.264887\n6.601779\n\n\n\n\n\nmodel_table_4 &lt;- child_l2_data %&gt;%\n  lm(formula = Oral_Production_Post ~ Oral_Production_Pre + group)\n\nsummary(model_table_4)\n\n\nCall:\nlm(formula = Oral_Production_Post ~ Oral_Production_Pre + group, \n    data = .)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-41.942 -21.363  -4.573  21.869  66.482 \n\nCoefficients:\n                    Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)          28.0406     5.2577   5.333 1.72e-06 ***\nOral_Production_Pre   1.3947     0.4662   2.991   0.0041 ** \ngroup2              -15.9727     6.9541  -2.297   0.0253 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 26.93 on 57 degrees of freedom\nMultiple R-squared:  0.2022,    Adjusted R-squared:  0.1742 \nF-statistic: 7.222 on 2 and 57 DF,  p-value: 0.001601\n\neffect(\"group\", model_table_4) %&gt;%\n  data.frame() %&gt;%\n  ggplot(aes(x = group,\n             y = fit,\n             ymin = lower,\n             ymax = upper)) +\n  geom_errorbar() +\n  geom_label(aes(label = format(fit, digits = 2)))"
  },
  {
    "objectID": "2023-09-01.html#visualizations-by-group",
    "href": "2023-09-01.html#visualizations-by-group",
    "title": "Reproducing Open Science Research 1",
    "section": "Visualizations by Group",
    "text": "Visualizations by Group\nOral production mean by group. We need to transform the data first, to have pre and post tests as values in a variable.\n\noral_production &lt;- child_l2_data %&gt;% \n  select(Participant, Group, Oral_Production_Pre, Oral_Production_Post) %&gt;% \n  pivot_longer(cols = c(Oral_Production_Pre, Oral_Production_Post)) %&gt;% \n  mutate(group = factor(Group),\n         name = factor(name,\n                       levels = c(\"Oral_Production_Pre\",\n                                  \"Oral_Production_Post\")))\n\nWe can now create a boxplot by group and type of test.\n\noral_production %&gt;% \n  ggplot(aes(x = group,\n             y = value,\n             color = name)) +\n  geom_boxplot()"
  },
  {
    "objectID": "2023-09-29.html#dependent-variable-status-intelligencework-ethic",
    "href": "2023-09-29.html#dependent-variable-status-intelligencework-ethic",
    "title": "Reproducing Open Science Research 3",
    "section": "dependent variable: status (intelligence/work ethic)",
    "text": "dependent variable: status (intelligence/work ethic)\n\nl2_span_perception &lt;- l2_span_perception %&gt;% \n  mutate(dep_status = Intelligent + Hardworking)\n\n\nlibrary(lme4)\nlibrary(lmerTest)\nmodel_status &lt;- lmer(dep_status ~ VariantHeard + SpeakerType + PhoneticsClass +\n                     MaxClassBinned + WeeksAbroad + AspirationContact +\n                     UseWithNSs + UseAtWork + UseListeningToMedia + Age +\n                     Gender + (1|Participant) + (1|AudioNumber),\n                   data = l2_span_perception)\n\nstep_model_status &lt;- step(model_status)\nstep_model_status\n\nBackward reduced random-effect table:\n\n                  Eliminated npar  logLik    AIC     LRT Df Pr(&gt;Chisq)    \n&lt;none&gt;                         17 -1273.4 2580.8                          \n(1 | Participant)          0   16 -1378.3 2788.6 209.844  1  &lt; 2.2e-16 ***\n(1 | AudioNumber)          0   16 -1284.0 2600.0  21.204  1  4.129e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nBackward reduced fixed-effect table:\nDegrees of freedom method: Satterthwaite \n\n                    Eliminated  Sum Sq Mean Sq NumDF  DenDF F value Pr(&gt;F)  \nGender                       1  0.0623  0.0623     1 64.000  0.0474 0.8283  \nVariantHeard                 2  0.1440  0.1440     1  7.000  0.1096 0.7503  \nAge                          3  0.1393  0.1393     1 65.000  0.1060 0.7458  \nUseListeningToMedia          4  2.3116  2.3116     1 66.000  1.7593 0.1893  \nSpeakerType                  5  2.9501  2.9501     1  8.000  2.2453 0.1724  \nUseAtWork                    6  2.6552  2.6552     1 67.000  2.0209 0.1598  \nWeeksAbroad                  7  2.9120  2.9120     1 67.999  2.2163 0.1412  \nUseWithNSs                   8  2.2384  2.2384     1 68.998  1.7036 0.1962  \nPhoneticsClass               9  3.5431  3.5431     1 70.000  2.6967 0.1050  \nAspirationContact           10  3.4437  3.4437     1 71.000  2.6210 0.1099  \nMaxClassBinned              11 10.3315  3.4438     3 72.000  2.6211 0.0572 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nModel found:\ndep_status ~ (1 | Participant) + (1 | AudioNumber)\n\n\n\nmodel_status_2 &lt;- lmer(dep_status ~ VariantHeard + PhoneticsClass +\n                         VariantHeard:PhoneticsClass +\n                     MaxClassBinned + (1|Participant) + (1|AudioNumber),\n                   data = l2_span_perception)\n\nsummary(model_status_2)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: \ndep_status ~ VariantHeard + PhoneticsClass + VariantHeard:PhoneticsClass +  \n    MaxClassBinned + (1 | Participant) + (1 | AudioNumber)\n   Data: l2_span_perception\n\nREML criterion at convergence: 2540.6\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-4.1648 -0.4831  0.0043  0.5349  3.3504 \n\nRandom effects:\n Groups      Name        Variance Std.Dev.\n Participant (Intercept) 0.94126  0.9702  \n AudioNumber (Intercept) 0.09798  0.3130  \n Residual                1.31438  1.1465  \nNumber of obs: 760, groups:  Participant, 76; AudioNumber, 10\n\nFixed effects:\n                                 Estimate Std. Error        df t value Pr(&gt;|t|)\n(Intercept)                       0.93969    0.26326  48.79329   3.569 0.000815\nVariantHeards                     0.03584    0.21773   8.45553   0.165 0.873137\nPhoneticsClassYes                -0.65228    0.36181  87.41817  -1.803 0.074864\nMaxClassBinnedElementary         -1.11418    0.42631  71.00059  -2.614 0.010932\nMaxClassBinnedIntermediate High   0.17895    0.29424  71.00059   0.608 0.545003\nMaxClassBinnedIntermediate Low   -0.34794    0.32749  71.00059  -1.062 0.291635\nVariantHeards:PhoneticsClassYes   0.19766    0.22810 674.00008   0.867 0.386480\n                                   \n(Intercept)                     ***\nVariantHeards                      \nPhoneticsClassYes               .  \nMaxClassBinnedElementary        *  \nMaxClassBinnedIntermediate High    \nMaxClassBinnedIntermediate Low     \nVariantHeards:PhoneticsClassYes    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) VrntHr PhntCY MxClBE MxCBIH MxCBIL\nVariantHrds -0.414                                   \nPhntcsClssY -0.342  0.052                            \nMxClssBnndE -0.425  0.000  0.198                     \nMxClssBnnIH -0.529  0.000  0.046  0.327              \nMxClssBnnIL -0.553  0.000  0.258  0.341  0.426       \nVrntHrd:PCY  0.068 -0.165 -0.315  0.000  0.000  0.000\n\nanova(model_status_2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSum Sq\nMean Sq\nNumDF\nDenDF\nF value\nPr(&gt;F)\n\n\n\n\nVariantHeard\n0.4566423\n0.4566423\n1\n10.24927\n0.3474209\n0.5683413\n\n\nPhoneticsClass\n3.4147173\n3.4147173\n1\n71.00059\n2.5979723\n0.1114373\n\n\nMaxClassBinned\n12.9231579\n4.3077193\n3\n71.00059\n3.2773827\n0.0258835\n\n\nVariantHeard:PhoneticsClass\n0.9870502\n0.9870502\n1\n674.00008\n0.7509638\n0.3864796\n\n\n\n\n\n\n\nlibrary(MuMIn)\nr.squaredGLMM(model_status_2)\n\n            R2m       R2c\n[1,] 0.06094177 0.4755826"
  },
  {
    "objectID": "2023-09-29.html#factor-analysis",
    "href": "2023-09-29.html#factor-analysis",
    "title": "Reproducing Open Science Research 3",
    "section": "Factor Analysis",
    "text": "Factor Analysis\n\n“[…] we conducted an FA and used the Kaiser Rules to establish which properties should be combined and analyzed as joint factors in the model-construction procedure”\n\nFor the Factor Analysis we need a data frame with only the indices we will be running on the analysis.\n\nindices &lt;- l2_span_perception %&gt;% \n  select(Intelligent:Feminine)\n\nNow we can run the FA (with 3 factors, since that’s what the authors did).\n\nfa &lt;- factanal(x = indices, factors = 3) \nfa\n\n\nCall:\nfactanal(x = indices, factors = 3)\n\nUniquenesses:\nIntelligent Hardworking        Nice    Hispanic   Confident DowntoEarth \n      0.351       0.407       0.536       0.487       0.415       0.303 \nGoodSpanish    Feminine \n      0.469       0.771 \n\nLoadings:\n            Factor1 Factor2 Factor3\nIntelligent  0.200   0.780         \nHardworking  0.291   0.680   0.213 \nNice         0.176   0.427   0.500 \nHispanic     0.698   0.127         \nConfident    0.647   0.406         \nDowntoEarth  0.107           0.827 \nGoodSpanish  0.673   0.258   0.109 \nFeminine    -0.443          -0.160 \n\n               Factor1 Factor2 Factor3\nSS loadings      1.723   1.509   1.028\nProportion Var   0.215   0.189   0.129\nCumulative Var   0.215   0.404   0.533\n\nTest of the hypothesis that 3 factors are sufficient.\nThe chi square statistic is 56.19 on 7 degrees of freedom.\nThe p-value is 8.66e-10 \n\n\nThen we inspect the loadings.\n\nfa$loadings\n\n\nLoadings:\n            Factor1 Factor2 Factor3\nIntelligent  0.200   0.780         \nHardworking  0.291   0.680   0.213 \nNice         0.176   0.427   0.500 \nHispanic     0.698   0.127         \nConfident    0.647   0.406         \nDowntoEarth  0.107           0.827 \nGoodSpanish  0.673   0.258   0.109 \nFeminine    -0.443          -0.160 \n\n               Factor1 Factor2 Factor3\nSS loadings      1.723   1.509   1.028\nProportion Var   0.215   0.189   0.129\nCumulative Var   0.215   0.404   0.533\n\n\nSS (sums of squares) loadings indicate the variance explained (eigenvalue/number of variables).\n\nThe FA motivated the creation of three combined factors: (a) a status factor (loading for intelligence and work ethic), (b) a confident Spanish-speaker factor (loading for Hispanicity, confidence, and good Spanish), and (c) a solidarity factor (loading for niceness and humility). As no other factors appeared to be correlated, they were explored independently.\n\n\nlibrary(psych)\nscree(indices)\n\n\n\n\nYou can learn more about FA in this chapter by Rachael Smyth and Andrew Johnson."
  },
  {
    "objectID": "2023-09-29.html#regression-models",
    "href": "2023-09-29.html#regression-models",
    "title": "Reproducing Open Science Research 3",
    "section": "Regression models",
    "text": "Regression models\n\nMixed-effects regression models were then created using the lme4 (Bates et al., Reference Bates, Maechler, Bolker and Walker2017) and lmerTest (Kuznetsova et al., Reference Kuznetsova, Brockhoff and Christensen2016) packages in R (R Core Team, 2018), and individual models were fitted to the following dependent variables: (a) status (intelligence/work ethic), (b) confident Spanish speaker (Hispanicity/confidence/good Spanish), (c) solidarity (niceness/humility), (d) age, (e) femininity, and (f) perceived speaker origin. Treatment contrasts were used, and the random effects in each model included the listener and the presentation order of the stimuli.\n\n\nThe independent variables tested in each model include variant ([s] or [h]), speaker type (Mexican or Puerto Rican), having taken a phonetics class (yes or no), most advanced Spanish class taken divided into four collapsed categories (elementary, intermediate low, intermediate high, and advanced), number of weeks spent studying abroad (continuous), experience abroad with an aspirating variety (yes or no), whether participants use Spanish regularly with NSs (yes or no), whether participants use Spanish regularly at work (yes or no), whether participants listen regularly to Spanish media (e.g., shows, podcasts, movies, music [yes or no]), listener age (continuous), and listener gender (man, woman, or other).\n\n\ndependent variable: status (intelligence/work ethic)\n\nl2_span_perception &lt;- l2_span_perception %&gt;% \n  mutate(dep_status = Intelligent + Hardworking)\n\n\nlibrary(lme4)\nlibrary(lmerTest)\nmodel_status &lt;- lmer(dep_status ~ VariantHeard + SpeakerType + PhoneticsClass +\n                     MaxClassBinned + WeeksAbroad + AspirationContact +\n                     UseWithNSs + UseAtWork + UseListeningToMedia + Age +\n                     Gender + (1|Participant) + (1|AudioNumber),\n                   data = l2_span_perception)\n\nstep_model_status &lt;- step(model_status)\nstep_model_status\n\nBackward reduced random-effect table:\n\n                  Eliminated npar  logLik    AIC     LRT Df Pr(&gt;Chisq)    \n&lt;none&gt;                         17 -1273.4 2580.8                          \n(1 | Participant)          0   16 -1378.3 2788.6 209.844  1  &lt; 2.2e-16 ***\n(1 | AudioNumber)          0   16 -1284.0 2600.0  21.204  1  4.129e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nBackward reduced fixed-effect table:\nDegrees of freedom method: Satterthwaite \n\n                    Eliminated  Sum Sq Mean Sq NumDF  DenDF F value Pr(&gt;F)  \nGender                       1  0.0623  0.0623     1 64.000  0.0474 0.8283  \nVariantHeard                 2  0.1440  0.1440     1  7.000  0.1096 0.7503  \nAge                          3  0.1393  0.1393     1 65.000  0.1060 0.7458  \nUseListeningToMedia          4  2.3116  2.3116     1 66.000  1.7593 0.1893  \nSpeakerType                  5  2.9501  2.9501     1  8.000  2.2453 0.1724  \nUseAtWork                    6  2.6552  2.6552     1 67.000  2.0209 0.1598  \nWeeksAbroad                  7  2.9120  2.9120     1 67.999  2.2163 0.1412  \nUseWithNSs                   8  2.2384  2.2384     1 69.000  1.7036 0.1961  \nPhoneticsClass               9  3.5431  3.5431     1 70.000  2.6967 0.1050  \nAspirationContact           10  3.4437  3.4437     1 71.000  2.6210 0.1099  \nMaxClassBinned              11 10.3315  3.4438     3 72.000  2.6211 0.0572 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nModel found:\ndep_status ~ (1 | Participant) + (1 | AudioNumber)\n\n\n\nmodel_status_2 &lt;- lmer(dep_status ~ VariantHeard + PhoneticsClass +\n                         VariantHeard:PhoneticsClass +\n                     MaxClassBinned + (1|Participant) + (1|AudioNumber),\n                   data = l2_span_perception)\n\nsummary(model_status_2)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: \ndep_status ~ VariantHeard + PhoneticsClass + VariantHeard:PhoneticsClass +  \n    MaxClassBinned + (1 | Participant) + (1 | AudioNumber)\n   Data: l2_span_perception\n\nREML criterion at convergence: 2540.6\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-4.1648 -0.4831  0.0043  0.5349  3.3504 \n\nRandom effects:\n Groups      Name        Variance Std.Dev.\n Participant (Intercept) 0.94126  0.9702  \n AudioNumber (Intercept) 0.09798  0.3130  \n Residual                1.31438  1.1465  \nNumber of obs: 760, groups:  Participant, 76; AudioNumber, 10\n\nFixed effects:\n                                 Estimate Std. Error        df t value Pr(&gt;|t|)\n(Intercept)                       0.93969    0.26326  48.79329   3.569 0.000815\nVariantHeards                     0.03584    0.21773   8.45553   0.165 0.873137\nPhoneticsClassYes                -0.65228    0.36181  87.41817  -1.803 0.074864\nMaxClassBinnedElementary         -1.11418    0.42631  71.00059  -2.614 0.010932\nMaxClassBinnedIntermediate High   0.17895    0.29424  71.00059   0.608 0.545003\nMaxClassBinnedIntermediate Low   -0.34794    0.32749  71.00059  -1.062 0.291635\nVariantHeards:PhoneticsClassYes   0.19766    0.22810 674.00008   0.867 0.386480\n                                   \n(Intercept)                     ***\nVariantHeards                      \nPhoneticsClassYes               .  \nMaxClassBinnedElementary        *  \nMaxClassBinnedIntermediate High    \nMaxClassBinnedIntermediate Low     \nVariantHeards:PhoneticsClassYes    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) VrntHr PhntCY MxClBE MxCBIH MxCBIL\nVariantHrds -0.414                                   \nPhntcsClssY -0.342  0.052                            \nMxClssBnndE -0.425  0.000  0.198                     \nMxClssBnnIH -0.529  0.000  0.046  0.327              \nMxClssBnnIL -0.553  0.000  0.258  0.341  0.426       \nVrntHrd:PCY  0.068 -0.165 -0.315  0.000  0.000  0.000\n\nanova(model_status_2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSum Sq\nMean Sq\nNumDF\nDenDF\nF value\nPr(&gt;F)\n\n\n\n\nVariantHeard\n0.4566423\n0.4566423\n1\n10.24927\n0.3474209\n0.5683413\n\n\nPhoneticsClass\n3.4147173\n3.4147173\n1\n71.00059\n2.5979723\n0.1114373\n\n\nMaxClassBinned\n12.9231579\n4.3077193\n3\n71.00059\n3.2773827\n0.0258835\n\n\nVariantHeard:PhoneticsClass\n0.9870502\n0.9870502\n1\n674.00008\n0.7509638\n0.3864796\n\n\n\n\n\n\n\nlibrary(MuMIn)\nr.squaredGLMM(model_status_2)\n\n            R2m       R2c\n[1,] 0.06094177 0.4755826\n\n\n\n\nspeakers’ perceived place of origin (Caribbean vs. other)\nTable 2 replication\n\nl2_span_perception &lt;- l2_span_perception %&gt;% \n  mutate(origin_dep = if_else(PerceivedSpeakerOrigin == \"Caribbean\", 1, 0),\n         VariantHeard = factor(VariantHeard, levels = c(\"s\", \"h\")))\n\nmodel_origin &lt;- lmer(origin_dep ~ VariantHeard + PhoneticsClass +\n                         VariantHeard:PhoneticsClass +\n                     MaxClassBinned + (1|Participant) + (1|AudioNumber),\n                   data = l2_span_perception)\n\nsummary(model_origin)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: \norigin_dep ~ VariantHeard + PhoneticsClass + VariantHeard:PhoneticsClass +  \n    MaxClassBinned + (1 | Participant) + (1 | AudioNumber)\n   Data: l2_span_perception\n\nREML criterion at convergence: 717.9\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.2038 -0.5766 -0.2064  0.3768  2.7826 \n\nRandom effects:\n Groups      Name        Variance Std.Dev.\n Participant (Intercept) 0.025294 0.15904 \n AudioNumber (Intercept) 0.004444 0.06666 \n Residual                0.129384 0.35970 \nNumber of obs: 760, groups:  Participant, 76; AudioNumber, 10\n\nFixed effects:\n                                 Estimate Std. Error        df t value Pr(&gt;|t|)\n(Intercept)                       0.28275    0.05281  33.89773   5.354 6.02e-06\nVariantHeardh                     0.13750    0.05085   8.85226   2.704   0.0246\nPhoneticsClassYes                -0.08467    0.07404 119.68607  -1.144   0.2551\nMaxClassBinnedElementary         -0.20150    0.08048  70.99993  -2.504   0.0146\nMaxClassBinnedIntermediate High  -0.07540    0.05555  70.99993  -1.357   0.1790\nMaxClassBinnedIntermediate Low   -0.29595    0.06183  70.99993  -4.787 8.96e-06\nVariantHeardh:PhoneticsClassYes   0.42917    0.07156 674.00004   5.997 3.28e-09\n                                   \n(Intercept)                     ***\nVariantHeardh                   *  \nPhoneticsClassYes                  \nMaxClassBinnedElementary        *  \nMaxClassBinnedIntermediate High    \nMaxClassBinnedIntermediate Low  ***\nVariantHeardh:PhoneticsClassYes ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) VrntHr PhntCY MxClBE MxCBIH MxCBIL\nVariantHrdh -0.481                                   \nPhntcsClssY -0.330  0.107                            \nMxClssBnndE -0.400  0.000  0.183                     \nMxClssBnnIH -0.498  0.000  0.043  0.327              \nMxClssBnnIL -0.520  0.000  0.238  0.341  0.426       \nVrntHrd:PCY  0.107 -0.222 -0.483  0.000  0.000  0.000\n\nanova(model_origin)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSum Sq\nMean Sq\nNumDF\nDenDF\nF value\nPr(&gt;F)\n\n\n\n\nVariantHeard\n5.2451299\n5.2451299\n1\n12.36777\n40.539246\n0.0000311\n\n\nPhoneticsClass\n0.5196316\n0.5196316\n1\n70.99993\n4.016197\n0.0488812\n\n\nMaxClassBinned\n3.1974421\n1.0658140\n3\n70.99993\n8.237603\n0.0000890\n\n\nVariantHeard:PhoneticsClass\n4.6530702\n4.6530702\n1\n674.00004\n35.963258\n0.0000000\n\n\n\n\n\nr.squaredGLMM(model_origin)\n\n          R2m       R2c\n[1,] 0.184729 0.3370942\n\n\n\nTo clarify this rather complex relationship, a conditional inference tree is provided in Figure 2.\n\nOh no\n\nlibrary(effects)\nlibrary(ggthemes)\neffect(\"VariantHeard:PhoneticsClass\", model_origin) %&gt;% \n  data.frame() %&gt;% \n  ggplot(aes(x = PhoneticsClass,\n             y = fit,\n             ymin = lower,\n             ymax = upper,\n             color = VariantHeard)) +\n  geom_errorbar() +\n  geom_label(aes(label = round(fit, 2))) +\n  theme_linedraw() +\n  scale_color_colorblind() +\n  labs(title = \"Probability (fit) of participant saying speaker is Caribbean\")\n\n\n\n\n\neffect(\"MaxClassBinned\", model_origin) %&gt;% \n  data.frame() %&gt;% \n  mutate(MaxClassBinned = factor(MaxClassBinned,\n                                 levels = c(\"Elementary\",\n                                            \"Intermediate Low\",\n                                            \"Intermediate High\",\n                                            \"Advanced\"))) %&gt;% \n  ggplot(aes(x = MaxClassBinned,\n             y = fit,\n             ymin = lower,\n             ymax = upper)) +\n  geom_errorbar() +\n  geom_label(aes(label = round(fit, 2))) +\n  theme_linedraw() +\n  labs(title = \"Probability (fit) of participant saying speaker is Caribbean\")\n\n\n\n\n\n\nConditional Inference Trees\n\nlibrary(partykit)\nl2_span_perception &lt;- l2_span_perception %&gt;% \n  mutate(VariantHeard = factor(VariantHeard),\n         PhoneticsClass = factor(PhoneticsClass),\n         MaxClassBinned = factor(MaxClassBinned),\n         PerceivedSpeakerOrigin = factor(PerceivedSpeakerOrigin))\n\nctree_model =  ctree(PerceivedSpeakerOrigin ~ VariantHeard + PhoneticsClass + MaxClassBinned, \n                     data = l2_span_perception)\n\nplot(ctree_model)"
  }
]